{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a1984345-06eb-45ec-860c-f5debbac5526",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "enter your number 5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "120\n"
     ]
    }
   ],
   "source": [
    "n=int(input(\"enter your number\"))\n",
    "f=1\n",
    "for i in range(1,n+1):\n",
    "    f=f*i\n",
    "print(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a550085e-3538-45be-937b-9507154f28c7",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import numpy\n",
    "X=[]\n",
    "#model=LogisticRegression()\n",
    "Y=[]\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174c8f38-ec3f-454e-bc3f-6554d540c33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65d437b-df4e-4f03-94a4-b9f4a1c654e2",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Angry Faces"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "id": "1ae471ae-03f2-4d4c-ac26-65f43c155c5c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\angry')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95f98e4e-582e-43dd-a18a-b5b5b2cb7cb5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "1ac93784-3df6-4947-9eeb-dee766862d9f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\angry')\n",
    "imgs=os.listdir(r'd:\\images\\Angry')\n",
    "\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'd:/images/Angry/{img}')\n",
    "    img_clr=img_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"Angry Face\")\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d1fd1b6-4aed-449a-ab05-329f6e868318",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "b29c3517-e7e3-4491-a8a6-b0e3ac9ae106",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\fear')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "eb78982e-2c67-447a-b41c-2aec1c216a03",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\fear')\n",
    "imgs=os.listdir(r'd:\\images\\Sad')\n",
    "\n",
    "for im in imgs:\n",
    "    im_clr=cv2.imread(f'd:/images/Sad/{im}')\n",
    "    im_clr=im_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"SadFace\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "id": "d7601860-610a-4f60-961f-e77412589fc2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\disgust')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84531888-4111-4689-b0cd-766b3dc8517c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs=os.listdir(r'd:\\images\\Happy')\n",
    "\n",
    "for img in imgs:\n",
    "    #print(img)\n",
    "    img_clr=cv2.imread(f'd:/images/Happy/{img}')\n",
    "#print(img_clr)\n",
    "    img_clr=img_clr/255\n",
    "    #print(img_clr)\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"HappyFace\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "362607dc-8706-447a-b940-0f9adb101d0d",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1162"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\happy')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "950de66e-d504-485b-b98c-62c36c4617a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs=os.listdir(r'd:\\images\\Fear')\n",
    "\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'd:\\images\\Fear/{img}')\n",
    "    img_clr=img_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"Fear  Face\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "94a0b71b-471e-4979-b13c-39488c2a3404",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\neutral')\n",
    "#X\n",
    "#len(Y)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "90997451-8337-4290-a717-ccf7a2603948",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\neutral')\n",
    "\n",
    "\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'C:/Users/Administrator/train/train/neutral/{img}')\n",
    "    img_clr=img_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"Neutral  Face\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "id": "9570d8ed-0bb2-47a7-8eeb-34f46d10f7be",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\sad')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "624d1920-c2b1-4215-a73c-56cbb759f6fb",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\sad')\n",
    "\n",
    "\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'C:/Users/Administrator/train/train/sad/{img}')\n",
    "    img_clr=img_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"Sad  Face\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "id": "0f9e973c-6905-476f-9f05-9e0d92da307d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "#imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\surprise')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "025c4a14-9bbc-46eb-9a85-a4864de69dea",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\surprise')\n",
    "\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'C:/Users/Administrator/train/train/surprise/{img}')\n",
    "    img_clr=img_clr/255\n",
    "    X.append(img_clr.flatten())\n",
    "    Y.append(\"Surprise  Face\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a1758657-d050-4c02-8342-3963cf6ec1a2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "new=LogisticRegression()\n",
    "List_new=Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "474b4c12-8e94-4b2e-b196-a74678111fa4",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "D:\\Data all\\Lib\\site-packages\\sklearn\\linear_model\\_logistic.py:460: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<style>#sk-container-id-1 {color: black;}#sk-container-id-1 pre{padding: 0;}#sk-container-id-1 div.sk-toggleable {background-color: white;}#sk-container-id-1 label.sk-toggleable__label {cursor: pointer;display: block;width: 100%;margin-bottom: 0;padding: 0.3em;box-sizing: border-box;text-align: center;}#sk-container-id-1 label.sk-toggleable__label-arrow:before {content: \"▸\";float: left;margin-right: 0.25em;color: #696969;}#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {color: black;}#sk-container-id-1 div.sk-estimator:hover label.sk-toggleable__label-arrow:before {color: black;}#sk-container-id-1 div.sk-toggleable__content {max-height: 0;max-width: 0;overflow: hidden;text-align: left;background-color: #f0f8ff;}#sk-container-id-1 div.sk-toggleable__content pre {margin: 0.2em;color: black;border-radius: 0.25em;background-color: #f0f8ff;}#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {max-height: 200px;max-width: 100%;overflow: auto;}#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {content: \"▾\";}#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 input.sk-hidden--visually {border: 0;clip: rect(1px 1px 1px 1px);clip: rect(1px, 1px, 1px, 1px);height: 1px;margin: -1px;overflow: hidden;padding: 0;position: absolute;width: 1px;}#sk-container-id-1 div.sk-estimator {font-family: monospace;background-color: #f0f8ff;border: 1px dotted black;border-radius: 0.25em;box-sizing: border-box;margin-bottom: 0.5em;}#sk-container-id-1 div.sk-estimator:hover {background-color: #d4ebff;}#sk-container-id-1 div.sk-parallel-item::after {content: \"\";width: 100%;border-bottom: 1px solid gray;flex-grow: 1;}#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {background-color: #d4ebff;}#sk-container-id-1 div.sk-serial::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: 0;}#sk-container-id-1 div.sk-serial {display: flex;flex-direction: column;align-items: center;background-color: white;padding-right: 0.2em;padding-left: 0.2em;position: relative;}#sk-container-id-1 div.sk-item {position: relative;z-index: 1;}#sk-container-id-1 div.sk-parallel {display: flex;align-items: stretch;justify-content: center;background-color: white;position: relative;}#sk-container-id-1 div.sk-item::before, #sk-container-id-1 div.sk-parallel-item::before {content: \"\";position: absolute;border-left: 1px solid gray;box-sizing: border-box;top: 0;bottom: 0;left: 50%;z-index: -1;}#sk-container-id-1 div.sk-parallel-item {display: flex;flex-direction: column;z-index: 1;position: relative;background-color: white;}#sk-container-id-1 div.sk-parallel-item:first-child::after {align-self: flex-end;width: 50%;}#sk-container-id-1 div.sk-parallel-item:last-child::after {align-self: flex-start;width: 50%;}#sk-container-id-1 div.sk-parallel-item:only-child::after {width: 0;}#sk-container-id-1 div.sk-dashed-wrapped {border: 1px dashed gray;margin: 0 0.4em 0.5em 0.4em;box-sizing: border-box;padding-bottom: 0.4em;background-color: white;}#sk-container-id-1 div.sk-label label {font-family: monospace;font-weight: bold;display: inline-block;line-height: 1.2em;}#sk-container-id-1 div.sk-label-container {text-align: center;}#sk-container-id-1 div.sk-container {/* jupyter's `normalize.less` sets `[hidden] { display: none; }` but bootstrap.min.css set `[hidden] { display: none !important; }` so we also need the `!important` here to be able to override the default hidden behavior on the sphinx rendered scikit-learn.org. See: https://github.com/scikit-learn/scikit-learn/issues/21755 */display: inline-block !important;position: relative;}#sk-container-id-1 div.sk-text-repr-fallback {display: none;}</style><div id=\"sk-container-id-1\" class=\"sk-top-container\"><div class=\"sk-text-repr-fallback\"><pre>LogisticRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class=\"sk-container\" hidden><div class=\"sk-item\"><div class=\"sk-estimator sk-toggleable\"><input class=\"sk-toggleable__control sk-hidden--visually\" id=\"sk-estimator-id-1\" type=\"checkbox\" checked><label for=\"sk-estimator-id-1\" class=\"sk-toggleable__label sk-toggleable__label-arrow\">LogisticRegression</label><div class=\"sk-toggleable__content\"><pre>LogisticRegression()</pre></div></div></div></div></div>"
      ],
      "text/plain": [
       "LogisticRegression()"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "new.fit(X,Y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "dc02bc23-468d-4c51-852d-8a68ab05dcd8",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "8b5f005b-1f28-447f-ad39-aa7a6f346a20",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'C:/Users/Administrator/train/train/disgust/{img}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "e4b106d9-0a59-483b-97d6-8c317421a2da",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "im_clr=cv2.imread('C:/Users/Administrator/train/train/disgust/Training_680349.jpg')\n",
    "im_clr=im_clr/255\n",
    "k.append(im_clr.flatten())\n",
    "#YY.append(\"fear Face\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "id": "75734ab8-b1a0-4c68-ad44-ac8adb7cb798",
   "metadata": {},
   "outputs": [],
   "source": [
    "k=[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "09f2b87b-ffd0-4d13-b9ca-91ca0ac66da9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "4de21401-16d4-4ed1-978c-d02b687b08f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "model=joblib.load('d:/Facial_model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "09773b0b-e99e-4b75-82fe-498d2e894bba",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['d:/My_facial_expression_model/My_facial_new_2']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#joblib.dump(model1,'d:/My_facial_expression_model/My_facial_new_1')##save model_1 \n",
    "joblib.dump(new,'d:/My_facial_expression_model/My_facial_new_2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "6641a513-944b-4e97-a910-66cd51137eaa",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "model=joblib.load('d:/My_facial_expression_model/My_facial_new_1')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "0e1ecf66-c164-4669-b337-a53892ff969a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import joblib\n",
    "\n",
    "new=joblib.load('d:/My_facial_expression_model/My_facial_new_2')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "id": "d7d1350d-2df6-4751-82bb-bc714b343cb3",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HappyFace'], dtype='<U10')"
      ]
     },
     "execution_count": 292,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "k=[]\n",
    "import cv2\n",
    "\n",
    "#img=cv2.imread('d:/kirti.jpg')\n",
    "img=cv2.imread('d:/kirti.jpg')\n",
    "#print(img)\n",
    "img=cv2.resize(img,(150,150))\n",
    "\n",
    "#cv2.imshow('chhh',im_clr)\n",
    "\n",
    "img=img/255\n",
    "k.append(img.flatten())\n",
    "#YY.append(\"fear Face\")\n",
    "new.predict(k)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ad995bb2-f7ef-4463-aa02-ce218c2ff69b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sklearn\n",
    "import cv2\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "import os\n",
    "import numpy as np\n",
    "X=[]\n",
    "model=LogisticRegression()\n",
    "Y=[]\n",
    "\n",
    "import joblib\n",
    "\n",
    "model=joblib.load('d:/My_facial_expression_model/My_facial_new')\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4aecb431-8f68-4c2d-ba8a-fa693cf16fd9",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "kkk=[]\n",
    "\n",
    "import time\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# define a video capture object \n",
    "vid = cv2.VideoCapture(0) \n",
    "coordinates = (30,30)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontScale = 0.9\n",
    "color = (255,0,255)\n",
    "thickness = 1\n",
    "\n",
    "while(True): \n",
    "    ret, img1 = vid.read() \n",
    "    sample=img1\n",
    "    img=cv2.resize(img1,(48,48))\n",
    "    img=img/255\n",
    "     \n",
    "    #l.append(img.flatten())\n",
    "    img.flatten()\n",
    "    kk=model.predict([img.flatten()])\n",
    "    list_1=kk.tolist()\n",
    "    #for i in range(len(list_1)):\n",
    "        \n",
    "    textt=cv2.putText(img1, kk[0], coordinates, font, fontScale, color, thickness, 8)\n",
    "    img=cv2.resize(textt,(100,100))\n",
    "    cv2.imshow('frame', img1)\n",
    "    \n",
    "  \n",
    "    if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "        break\n",
    "fac = kk\n",
    "kk=np.array([])\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "2eaecc4b-9850-434d-adfa-1152d5e9fdf7",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'kk' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[86], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;66;03m#ll=model.predict(l)\u001b[39;00m\n\u001b[1;32m----> 2\u001b[0m kk\n\u001b[0;32m      3\u001b[0m \u001b[38;5;66;03m#kk=np.array([])\u001b[39;00m\n\u001b[0;32m      4\u001b[0m fac\n",
      "\u001b[1;31mNameError\u001b[0m: name 'kk' is not defined"
     ]
    }
   ],
   "source": [
    "#ll=model.predict(l)\n",
    "kk\n",
    "#kk=np.array([])\n",
    "fac\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "e8f704ad-aaf5-45ee-b62a-97e90ea1b8c8",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'cv2' has no attribute 'LIN'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 9\u001b[0m\n\u001b[0;32m      7\u001b[0m color \u001b[38;5;241m=\u001b[39m (\u001b[38;5;241m255\u001b[39m,\u001b[38;5;241m0\u001b[39m,\u001b[38;5;241m255\u001b[39m)\n\u001b[0;32m      8\u001b[0m thickness \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m----> 9\u001b[0m image \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mputText(image, text, coordinates, font, fontScale, color, thickness, cv2\u001b[38;5;241m.\u001b[39mLIN)\n\u001b[0;32m     10\u001b[0m cv2\u001b[38;5;241m.\u001b[39mimshow(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mText\u001b[39m\u001b[38;5;124m\"\u001b[39m, image)\n\u001b[0;32m     11\u001b[0m cv2\u001b[38;5;241m.\u001b[39mwaitKey(\u001b[38;5;241m0\u001b[39m)\n",
      "\u001b[1;31mAttributeError\u001b[0m: module 'cv2' has no attribute 'LIN'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "image = cv2.imread(\"d:/chhavi.jpeg\")\n",
    "text = \"TutorialsPoint\"\n",
    "coordinates = (30,30)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontScale = 0.9\n",
    "color = (255,0,255)\n",
    "thickness = 1\n",
    "image = cv2.putText(image, text, coordinates, font, fontScale, color, thickness, cv2.LIN)\n",
    "cv2.imshow(\"Text\", image)\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "06e58bc1-d86d-4561-8a9a-3091b84d103f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "k\n",
      "l\n",
      "p\n"
     ]
    }
   ],
   "source": [
    "kp=['k','l','p']\n",
    "import numpy as np\n",
    "arr=np.array(kp)\n",
    "\n",
    "for i in range(len(kp)):\n",
    "    print(kp[i])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "b5afc5a3-19db-4802-a724-aa892cd63f59",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "k=[]\n",
    "import cv2\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "imgs=os.listdir(r'C:\\Users\\Administrator\\train\\train\\surprise')\n",
    "\n",
    "c=0\n",
    "for img in imgs:\n",
    "    img_clr=cv2.imread(f'C:/Users/Administrator/train/train/surprise/{img}',0)\n",
    "\n",
    "    #im_clr=cv2.imread('C:/Users/Administrator/train/train/disgust/Training_680349.jpg')\n",
    "    img_clr=cv2.resize(img_clr,(150,150))\n",
    "    #cv2.imshow(\"this is my image\",im_clr)\n",
    "    cv2.imwrite(f'd:/images/Surprise/img{c}.png',img_clr)\n",
    "    c=c+1  \n",
    "    #k=str(c)            \n",
    "#im_clr=im_clr/255\n",
    "#k.append(im_clr.flatten())\n",
    "#YY.append(\"fear Face\")\n",
    "cv2.waitKey(0)\n",
    "cv2.destroyAllWindows() \n",
    "\n",
    "    \n",
    " \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "51ecbec6-33d1-41bb-ae9c-51c0b1a38bd2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 6912)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.shape(k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c079622-3f7c-454d-b983-8202664eda93",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "99ce93c3-9389-4b60-a779-6806d847b0c4",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "If using all scalar values, you must pass an index",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[7], line 5\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m      4\u001b[0m \u001b[38;5;66;03m# df = pd.read_excel(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\autoTestingPythonSelenium.xlsx\")\u001b[39;00m\n\u001b[1;32m----> 5\u001b[0m df\u001b[38;5;241m=\u001b[39mpd\u001b[38;5;241m.\u001b[39mDataFrame({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTC_ID\u001b[39m\u001b[38;5;124m'\u001b[39m:\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m78\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m      6\u001b[0m df\u001b[38;5;241m.\u001b[39mto_csv(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124md:/newAu1.csv\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[1;32mD:\\Data all\\Lib\\site-packages\\pandas\\core\\frame.py:709\u001b[0m, in \u001b[0;36mDataFrame.__init__\u001b[1;34m(self, data, index, columns, dtype, copy)\u001b[0m\n\u001b[0;32m    703\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_init_mgr(\n\u001b[0;32m    704\u001b[0m         data, axes\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mindex\u001b[39m\u001b[38;5;124m\"\u001b[39m: index, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcolumns\u001b[39m\u001b[38;5;124m\"\u001b[39m: columns}, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy\n\u001b[0;32m    705\u001b[0m     )\n\u001b[0;32m    707\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, \u001b[38;5;28mdict\u001b[39m):\n\u001b[0;32m    708\u001b[0m     \u001b[38;5;66;03m# GH#38939 de facto copy defaults to False only in non-dict cases\u001b[39;00m\n\u001b[1;32m--> 709\u001b[0m     mgr \u001b[38;5;241m=\u001b[39m dict_to_mgr(data, index, columns, dtype\u001b[38;5;241m=\u001b[39mdtype, copy\u001b[38;5;241m=\u001b[39mcopy, typ\u001b[38;5;241m=\u001b[39mmanager)\n\u001b[0;32m    710\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(data, ma\u001b[38;5;241m.\u001b[39mMaskedArray):\n\u001b[0;32m    711\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mma\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m mrecords\n",
      "File \u001b[1;32mD:\\Data all\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:481\u001b[0m, in \u001b[0;36mdict_to_mgr\u001b[1;34m(data, index, columns, dtype, typ, copy)\u001b[0m\n\u001b[0;32m    477\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    478\u001b[0m         \u001b[38;5;66;03m# dtype check to exclude e.g. range objects, scalars\u001b[39;00m\n\u001b[0;32m    479\u001b[0m         arrays \u001b[38;5;241m=\u001b[39m [x\u001b[38;5;241m.\u001b[39mcopy() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(x, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdtype\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01melse\u001b[39;00m x \u001b[38;5;28;01mfor\u001b[39;00m x \u001b[38;5;129;01min\u001b[39;00m arrays]\n\u001b[1;32m--> 481\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m arrays_to_mgr(arrays, columns, index, dtype\u001b[38;5;241m=\u001b[39mdtype, typ\u001b[38;5;241m=\u001b[39mtyp, consolidate\u001b[38;5;241m=\u001b[39mcopy)\n",
      "File \u001b[1;32mD:\\Data all\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:115\u001b[0m, in \u001b[0;36marrays_to_mgr\u001b[1;34m(arrays, columns, index, dtype, verify_integrity, typ, consolidate)\u001b[0m\n\u001b[0;32m    112\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verify_integrity:\n\u001b[0;32m    113\u001b[0m     \u001b[38;5;66;03m# figure out the index, if necessary\u001b[39;00m\n\u001b[0;32m    114\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m index \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m--> 115\u001b[0m         index \u001b[38;5;241m=\u001b[39m _extract_index(arrays)\n\u001b[0;32m    116\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m    117\u001b[0m         index \u001b[38;5;241m=\u001b[39m ensure_index(index)\n",
      "File \u001b[1;32mD:\\Data all\\Lib\\site-packages\\pandas\\core\\internals\\construction.py:645\u001b[0m, in \u001b[0;36m_extract_index\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m    642\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPer-column arrays must each be 1-dimensional\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    644\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m indexes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m raw_lengths:\n\u001b[1;32m--> 645\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIf using all scalar values, you must pass an index\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    647\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m have_series:\n\u001b[0;32m    648\u001b[0m     index \u001b[38;5;241m=\u001b[39m union_indexes(indexes)\n",
      "\u001b[1;31mValueError\u001b[0m: If using all scalar values, you must pass an index"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    " \n",
    "# df = pd.read_excel(\"C:\\\\Users\\\\Administrator\\\\Desktop\\\\autoTestingPythonSelenium.xlsx\")\n",
    "df=pd.DataFrame({'TC_ID':'78'})\n",
    "df.to_csv('d:/newAu1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "dd8ffd21-a7c3-4d5f-96ac-df22e1b2e4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "img=cv2.imread('d:/child.jpg')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ee01a09-13a2-4ac1-9577-6fb4dc08e9c0",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "886770d0-2160-49d5-b524-14abad96d0c5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "125107e4-94a1-417b-b61d-2214e87ef314",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f622fc1-cd58-46f9-bc7c-a39019901e8e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc0d6ffb-b683-4483-b013-e83ccc8d1ba4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b71272e8-9800-4990-a7d5-76767073aaed",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bab78130-f732-47b1-9369-21ee92f99c33",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "45c24f7d-8a6c-4f6d-a82f-07a17a2111c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'Y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[4], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m Y\n",
      "\u001b[1;31mNameError\u001b[0m: name 'Y' is not defined"
     ]
    }
   ],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c06d316f-b249-4398-bdc4-19b6d7826abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d9f7b9cf-d271-4127-8335-fb3e5a96b08a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import cv2 \n",
    "kkk=[]\n",
    "\n",
    "import time\n",
    "from selenium.webdriver.support.select import Select\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "\n",
    "# define a video capture object \n",
    "vid = cv2.VideoCapture(0) \n",
    "coordinates = (30,30)\n",
    "font = cv2.FONT_HERSHEY_DUPLEX\n",
    "fontScale = 0.9\n",
    "color = (255,0,255)\n",
    "thickness = 1\n",
    "\n",
    "while(True): \n",
    "    ret, img1 = vid.read() \n",
    "    sample=img1\n",
    "    img=cv2.resize(img1,(150,150))\n",
    "    img=img/255\n",
    "     \n",
    "    #l.append(img.flatten())\n",
    "    img.flatten()\n",
    "    kk=new.predict([img.flatten()])\n",
    "    list_1=kk.tolist()\n",
    "    #for i in range(len(list_1)):\n",
    "        \n",
    "    textt=cv2.putText(img1, kk[0], coordinates, font, fontScale, color, thickness, 8)\n",
    "    img=cv2.resize(textt,(150,150))\n",
    "    cv2.imshow('frame', img1)\n",
    "    \n",
    "    for i in List_new:\n",
    "        if i=='HappyFace':\n",
    "\n",
    "            options = Options()\n",
    "            options.add_experimental_option(\"detach\", True)\n",
    "            driver = webdriver.Chrome(options)\n",
    "            driver.get('https://www.youtube.com/watch?v=kXTk1kCD8Ko')\n",
    "            break\n",
    "\n",
    "            #driver.find_element(By.XPATH,\"(//button[@aria-label='Play keyboard shortcut k'])[1]\").click()\n",
    "\n",
    "            #print(kk[0])\n",
    "        elif i=='SadFace':\n",
    "            options = Options()\n",
    "            options.add_experimental_option(\"detach\", True)\n",
    "            driver = webdriver.Chrome(options)\n",
    "            driver.get('https://www.youtube.com/watch?v=El_VOjSzvuY')\n",
    "            break\n",
    "\n",
    "#         print(\"not found\")\n",
    "    \n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'): \n",
    "            break\n",
    "# fac = kk\n",
    "# kk=np.array([])\n",
    "# After the loop release the cap object \n",
    "vid.release() \n",
    "# Destroy all the windows \n",
    "cv2.destroyAllWindows() \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 297,
   "id": "2837d719-49d8-4c44-9f4d-7248dab75851",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['HappyFace'], dtype='<U10')"
      ]
     },
     "execution_count": 297,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fac"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9547f88-6270-41c0-94b7-b9ece72394db",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "8a6c7644-d0cd-4f8f-8a16-b6ac68ed8cc6",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'HappyFace'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64825dc8-ae8c-46ff-82ef-60229138db7f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
